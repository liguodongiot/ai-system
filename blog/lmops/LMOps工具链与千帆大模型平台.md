![image](https://github.com/liguodongiot/ai-system/assets/13220186/67ca3dd9-117d-4f8a-9bb2-c5151288814a)
- https://www.infoq.cn/article/o8abj2wff5yLfGWuB0E1


## 从机器学习到百模大战

大模型在技术和应用层面带来了哪些变化。比如在以下 4 个技术层面：

- 数据：大模型的预训练通常需要 TB-PB 级别的数据， TB-PB 级别的数据规模和对应的数据加工技术，与之前的经典深度学习模型并不相同。同时，大模型大多以多模态、指令、对话数据作为训练或调优的输入，在数据内容上和之前的经典深度学习模型也有很大的差异。

- 训练和调优的方法：现在千亿参数级别的大模型，往往需要千卡、甚至万卡进行分布式训练，其中的调度、容错、通信技术和之前大不相同。大模型在调优过程中也出现了很多低资源开销、高效率的技术。

- 大模型效果评估方式：经典深度学习模型往往基于人工标注的测试数据集，来计算客观指标，并评估模型效果。因为大模型生成的海量内容暂无标准的答案，所以我们无法全部依赖人工去评判内容的质量。因此，大模型的效果和性能需要建立与以往不同的评估基准和评估方法。

- 推理：通过 Prompt 工程来调教大模型的输出，无论是在自然语言处理还是视觉生成领域，之前经典的深度学习模型都不具备这些能力。

![](https://static001.geekbang.org/infoq/f2/f2b07b703539d708a8435bf849ff59aa.png)

![](https://static001.geekbang.org/infoq/ea/eaa21fe5ba18bf6094433cebe94b6517.png)



## DevOps、MLOps 和 LMOps 概念及相关技术


LMOps 继承了 MLOps 整体的框架和机器学习的全生命周期等主要环节，并且针对大模型的变化进行了微调适配。

在生成式大模型的数据组成中，无监督数据和未标注的数据在大幅度上升。
为了解决上述问题，LMOps 对无监督数据和未标注的数据加工进行了强化。对于传统的机器学习模型，我们经常需要修改代码来进行效果的强化和调整。
而在 LMOps 下，我们几乎不需要去修改大模型的代码，同时也会注重并行分布式训练大模型的效能的提升。

另外在 LMOps 中，针对大模型出现了新的提示工程（ Prompt 工程），从工具链的角度思考哪些方面可以更加自动化、提供提示词模板等也是 MLOps 中新引入的能力。



对于预训练模型的调优，在 LMOps 中也出现了新的方法，包括下文我们会介绍的 PEFT 、 SFT 方法等。近期还有另一个非常热门的方向，主要讨论针对大语言模型，如何通过插件的方式去扩展它的能力，开源社区也有一些很好的 API 框架由此诞生。对于这部分插件的能力， 在 LMOps 生命周期中需要同时被管理、做进一步的适配和优化。



综上所述，LMOps 继承了 MLOps 主体及框架，并在每个环节上都针对大模型的特点进行适配，形成新的技术实践。




[](https://static001.geekbang.org/infoq/98/986552f7ad5e597744d747736f712836.png)

虽然 LMOps 问世不久，但整个上下游的各类公司已经共同构建了繁荣的生态。
其中就包括向量数据库 Pinecone、以及我们非常熟悉的 OpenAI、Hugging Face、Stable Diffusion 等做模型及模型集成的厂商。
这也解释了为什么 MLOps 与 LMOps 在资本投入中占据很大比重。


![](https://static001.geekbang.org/infoq/d9/d97a2c2cc096baf8ff2d60d0dbeae8d3.png)



在了解了 LMOps 的相关概念之后，下面将为大家介绍 LMOps 在数据、训练、评估、推理、部署和安全这六个主要环节的核心技术。

### 数据处理



在数据加工的环节上，大模型在预训练和再训练的阶段，往往使用的是大规模未标注数据。
因此，对这些大规模未标注的数据进行加工和配比，对大模型的效果至关重要。数据加工环节包括五个步骤：

- 首先是对特殊字符的一些清除，如火星文 / 特殊的标点清除等，替换部分异常文本。

- 删除低质量文档。建立低质文档的统计指标，超过某个阈值就进行删除。或通过定制的分类模型对文档质量进行自动分类。

- 文档去重。通常情况下，我们可以针对文档中的句子和段落等进行文档内的内容去重；针对两个内容重复阈值较高的相似文档，可以进行跨文档去重。

- 去除隐私数据。使用基于规则的正则表达式的方法检测个人信息，来进行隐私数据的脱敏。

- 建立词表（ Tokenize 的过程）。目前建立此表常用的是 SentencePiece 等方法。当我们将原始的语料加工成 token，并建立 token_id 后，再喂给大模型进行训练或者推理。

对于数据加工的环境，我分享一下自己的心得。

决定大模型效果的，并不主要是模型结构和参数配置，而是数据的质量和配比，对大模型的效果会产生更加重要的影响。

比如：训练大模型需要哪些来源的数据、数据的比例分配，通过加工步骤后数据的质量和多样性决定了预训练后大模型的效果。


![](https://static001.geekbang.org/infoq/ff/ff3de7bb8125197cca917629e7ab94f4.png)


### 模型训练

LMOps 训练环节的核心技术，包括监督调优和基于人工反馈的强化学习。
如下图所示，SFT （Supervised Fine Tuning）通过包含指令和提示数据的人工标注生成结果对大语言模型进行调优，能够较好地激发大模型的场景化能力和生成效果。
RLHF（Reinforcement Learning from Human Feedback ）能够让大语言模型优先生成最符合人类喜好和价值观的结果。
这也是目前大语言模型调优一定会做的技术，所以 RLHF 是 LMOps 训练环节的核心技术之一。

![](https://static001.geekbang.org/infoq/e5/e5a81ebf563a72bc100e2a08ae547aea.png)

除 SFT、RLHF 技术外，近期 PEFT 技术也非常热门，是目前大语言模型调优环节中广泛采用的技术，它是一系列高效率微调技术的总称。



大模型的参数量一般在十亿甚至百亿、千亿、万亿以上。如果按照传统的机器学习模型或经典的深度学习模型，对大模型的全量参数进行调优（再训练）会造成资源开销超负荷。并且，对大模型的全量参数进行调优，可能会把预训练的模型训坏掉，丧失大模型原有的能力和效果。针对此问题，研究者提出微量调优（针对少部分参数进行调优）的办法。所以，目前常用 PEFT 手段对大模型进行调优。



### 模型评估

对于大模型的评估，我们需要围绕评估标准、评测集、评估任务提示模板、评估工具四方面重新建立评估的流程，这四方面也是 LMOps 独有的特点：



对于大模型的评估我们需要建立新的评估标准，包括针对效果、性能、安全性、生态多样性等各个维度的评估。这些能力都需要在 LMOps 中构建相应的大规模的评估标准来实现。



在过去，针对经典的深度学习的模型已经有 Benchmark 存在，但是当大模型出现之后，发现这些已经存在的评测集已经不够用了。有些小规模的评测集可能已经包含在大语言模型的训练数据当中了，再去利用这些 Benchmark 做评估，它就没有区分度了，所以新的大规模的评测集需要构建起来。



因为大语言模型的能力在不断增强，所以评测集涵盖的方向需要进一步的拓展，包括像数学、历史、图像生成等跨模态等。



在评估环节，已经不是单纯的用一个指令或者 Query 输入去评估大模型的输出了，而是说会结合不同的评估模板，让机器去做自动的评估，包括通过让大语言模型去做选择题。这样的话就可以更加客观地评估在实际的使用过程中如何提升它的效果。



和评估环节相应的是评估工具，包括人工可操作的、以及面向机器的评估工具来进行自动化的评估。

在评估环节，以上四个方面是 LMOps 中新增和特有的。

![](https://static001.geekbang.org/infoq/2f/2f73116c4a337ba56d083254289d9417.png)


## 模型推理


在推理环节中，LMOps 中最明显的变化就是引入了 Prompt 工程（提示工程）。一个标准的 Prompt 模板，包括对任务背景的陈述，然后提供一些相关的上下文的材料。其中很重要的一点，就是如果能提供一些示例，也称为 few shot，那么大语言模型的输出的效果会显著的有一个提升，最后再加上这次输入的 Query。



而针对提示模板的构建，也有一系列的要求和实践指导。比如，提示模板的首要要求是安全无害的内容，意图本身模板足够的规范、流畅，提供真实可信的材料等。每一个使用者都需要全部遵守提示模板的要求，但每一个使用者对 Prompt 的书写各有不同，所以遵守 Prompt 模板的要求实施难度较大。所以，在 LMOps 中出现了对应的自动化生成提示工具，为使用者提供提示模板，辅助整个大模型提示工程的实现。



在很多平台型的 LMOps 工具中，还会自带 Playground，让我们可以直接以对话的形式、或分类摘要等形式直接体验训练 / 调优完成的大模型效果。



在推理环节的最后一部分是基础的 API 服务。企业在自己的应用中使用大模型，通常将 API 与现有的业务集成，使得业务具备更加智能化的体验。从一个模型到服务，需要经历 API 授权、提供访问的 Token 凭证，并对调用进行流控、鉴权等。


![](https://static001.geekbang.org/infoq/32/323115addaf566d61ab96bd9a35b86a5.png)

在部署环节，因为大语言模型参数量很大，需要在服务器上做部署，依赖大规模的 GPU 和 CPU 的资源等。



但是如果需要把这些大模型的核心能力部署到边缘或者小型化的设备上，甚至于一些性能比较好的手机上，是否有实现的可能？大模型如果能做本地的部署，那么它的响应效率会更高，延迟会更低，数据的隐私性会更好。



在部署环节，LMops 会引入很多优化，包括量化、蒸馏、交叉编译、国产芯片适配等技术。

![](https://static001.geekbang.org/infoq/12/122b2d1c5db5da2ee0a276f0629523ef.png)


因为大模型的再训练、预训练的资源规模庞大，所以很多企业与个人用户是没有足够的算力资源去支撑他们完成相关任务。针对此情况，企业与个人用户需要依赖云端资源来满足自己的业务需求。
企业上云，如何保证数据的安全和隐私是企业考虑的重要因素。


下图为大家详细介绍的千帆大模型平台就在安全方面做了大量的优化工作。
比如千帆大模型平台进行数据加密（包括同态加密、差分隐私等）、为训练环节提供可信的计算环境（包括沙盒环境等），
以及在大模型完成部署进行推理的时候如何对数据进行加密、针对用户的隐私数据进行脱敏等。

![](https://static001.geekbang.org/infoq/9c/9c9d5858abfbec4deb6bb6267a200f3e.png)


















