


## GPU


### GPU 监控

- [【系统监控】GPU 监控](https://houmin.cc/posts/b4058e1b/)
- [CPU和GPU性能指标收集](https://blog.csdn.net/TH_NUM/article/details/128305548)
- [DCGM](https://docs.nvidia.com/datacenter/dcgm/latest/user-guide/index.html)
- [聊聊GPU利用率那些事](https://blog.csdn.net/u011458874/article/details/121020613)



## AI集群通信优化

- [AI框架基础技术之深度学习中的通信优化](https://mp.weixin.qq.com/s/CyRI3z9ABVliV5gF5gUfog#at)
- [AI框架基础技术之深度学习中的通信优化](https://zhuanlan.zhihu.com/p/348982652)
- [深度学习模型，有哪些最新的加速技术？](https://zhuanlan.zhihu.com/p/147204568)
- [大模型加速](https://zhuanlan.zhihu.com/p/614033090)



## LLM


### LLM 技术原理

#### RLHF
- [OpenAI联合创始人亲自上场科普GPT，让技术小白也能理解最强AI](https://mp.weixin.qq.com/s/MD4WwwJLXm8rEm-sniX8Gw)
- [详解大模型RLHF过程（配代码解读）](https://zhuanlan.zhihu.com/p/624589622)
- [ChatGPT 背后的“功臣”——RLHF 技术详解](https://huggingface.co/blog/zh/rlhf)，[Illustrating Reinforcement Learning from Human Feedback (RLHF)](https://huggingface.co/blog/rlhf)
- [为什么RLHF中，PPO需要Critic模型而不是直接使用Reward模型](https://www.cnblogs.com/end/p/17481052.html)
- [Advantage Actor Critic (A2C) - Hugging Face](https://huggingface.co/blog/deep-rl-a2c)
- [关于Instruct GPT复现的一些细节与想法](https://zhuanlan.zhihu.com/p/609078527)
- [ChatGPT会取代搜索引擎吗](https://zhuanlan.zhihu.com/p/589533490)
- [“StackLLaMA”: 用 RLHF 训练 LLaMA 的手把手教程](https://huggingface.co/blog/zh/rlhf)




## 数据并行


- http://zh.d2l.ai/chapter_computational-performance/parameterserver.html
- [DataParallel & DistributedDataParallel分布式训练](https://zhuanlan.zhihu.com/p/206467852)
- [PyTorch分布式训练简明教程(2022更新版)](https://zhuanlan.zhihu.com/p/113694038)
- [DataParallel 和 DistributedDataParallel 的区别和使用方法](https://blog.csdn.net/weixin_43402775/article/details/114318434)
- [PyTorch 源码解读之 DP & DDP：模型并行和分布式训练解析](https://zhuanlan.zhihu.com/p/343951042)
- [Pytorch 并行训练（DP， DDP）的原理和应用](https://blog.csdn.net/kuweicai/article/details/120516410)



## 多维混合并行

- [HF多维混合并行](https://huggingface.co/docs/transformers/perf_train_gpu_many)



## 流水线并行





## 博客

- Lilian（OpenAI）： https://lilianweng.github.io/  














